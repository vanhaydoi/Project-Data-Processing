# Real-Time & Batch Data Ingestion Platform
Ná»n táº£ng xá»­ lÃ½ dá»¯ liá»‡u thá»i gian thá»±c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« nhiá»u nguá»“n khÃ¡c nhau, bao gá»“m luá»“ng streaming vÃ  batch processing. Framework nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn dÆ°á»›i dáº¡ng cÃ¡c package riÃªng biá»‡t vÃ  Ä‘Æ°á»£c publish lÃªn PyPI Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng dá»… dÃ ng.
# ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng
flowchart LR
  %% NhÃ³m nguá»“n dá»¯ liá»‡u
  subgraph DataSources["Data Sources"]
    Kaf["Kafka Streaming\n18.211.252.152:9092\ntopic: de-capstone3"]
    JSON["JSON Files\n(Batch Input)"]
    Airflow["Apache Airflow\n(Orchestration)"]
  end

  %% NhÃ³m xá»­ lÃ½ Spark
  subgraph Spark["Apache Spark Processing"]
    SS["Spark Streaming\n(Real-time)"]
    PB["Python Batch Jobs\n(Scheduled Processing)"]
  end

  %% NhÃ³m lÆ°u trá»¯ HDFS
  subgraph HDFS["Hadoop HDFS Data Lake"]
    RAW["RAW\n(Raw Data)"] --> STG["STAGING\n(Cleaned)"] --> MART["MART\n(Analytics Ready)"]
  end

  %% CÃ¡c káº¿t ná»‘i chÃ­nh
  Kaf --> SS
  JSON --> PB
  Airflow --> PB

  SS --> RAW
  PB --> RAW

  MART --> Hive["Apache Hive\n(Metadata & SQL Analytics)"] --> BI["Power BI\n(via ODBC Connection)"]

# âœ¨ TÃ­nh nÄƒng chÃ­nh
## ğŸŒŠ Streaming Data Processing
- Thu tháº­p dá»¯ liá»‡u real-time tá»« Apache Kafka
- Xá»­ lÃ½ JSON data vá»›i Apache Spark Streaming
- Ghi dá»¯ liá»‡u trá»±c tiáº¿p vÃ o HDFS RAW zone
## ğŸ“¦ Batch Data Processing
- Xá»­ lÃ½ file JSON theo lá»‹ch trÃ¬nh Ä‘á»‹nh ká»³
- TÃ­ch há»£p vá»›i Python batch jobs
- Há»— trá»£ multiple data sources
## ğŸ­ ETL Pipeline
- Pipeline 3 táº§ng: RAW â†’ STAGING â†’ MART
- Data transformation vÃ  cleansing
- Schema normalization vÃ  data enrichment
- Partitioning theo ngÃ y (partitioned by dt)
## ğŸ›ï¸ Orchestration & Monitoring
- Quáº£n lÃ½ workflow vá»›i Apache Airflow
- LÃªn lá»‹ch cháº¡y Ä‘á»‹nh ká»³ (daily/hourly)
- Data quality monitoring
- Job dependency management
# âš™ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng
## CÃ´ng nghá»‡ sá»­ dá»¥ng

| CÃ´ng nghá»‡ | PhiÃªn báº£n | Má»¥c Ä‘Ã­ch |
|:-----------|:-----------|:----------|
| Apache Kafka | 2.8+ | Message streaming platform |
| Apache Spark | 3.3+ | Distributed data processing |
| Hadoop HDFS | 3.3+ | Distributed file storage |
| Apache Hive | 3.1+ | Data warehouse vÃ  SQL analytics |
| Apache Airflow | 2.5+ | Workflow orchestration |
| Python | 3.8+ | Batch processing scripts |
| Docker | 20.10+ | Containerization |
| Power BI | Latest | Business intelligence vÃ  visualization |
# ğŸš€ CÃ i Ä‘áº·t
- Python 3.8+
- Docker & Docker Compose
- Java 8/11 (cho Spark vÃ  Hadoop)
- Minimum 8GB RAM
- 50GB storage space
# CÃ i Ä‘áº·t tá»« PyPI
## CÃ i Ä‘áº·t cÃ¡c framework tá»« PyPI
pip install de-streaming-ingestion-framework
pip install de-batch-ingestion-framework  
pip install de-hdfs-elt-framework
# ğŸ“ Cáº¥u trÃºc dá»± Ã¡n
realtime-data-processing/
â”œâ”€â”€ ğŸ“¦ de_streaming_ingestion_framework/    # Streaming framework
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ kafka_consumer.py
â”‚   â”‚   â”œâ”€â”€ spark_streaming.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ setup.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“¦ de_batch_ingestion_framework/        # Batch processing framework  
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ file_processor.py
â”‚   â”‚   â”œâ”€â”€ batch_job.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ setup.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“¦ de_hdfs_elt_framework/              # ETL framework
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ etl_jobs.py
â”‚   â”‚   â”œâ”€â”€ data_quality.py
â”‚   â”‚   â”œâ”€â”€ transformations.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ setup.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ›ï¸ de_dags/                           # Airflow orchestration
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ main_pipeline.py
â”‚   â”‚   â”œâ”€â”€ streaming_dag.py
â”‚   â”‚   â””â”€â”€ batch_dag.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.yml
â”‚   â”‚   â””â”€â”€ airflow.cfg
â”‚   â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ³ docker/                            # Docker configurations
â”‚   â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ hadoop/
â”‚   â””â”€â”€ kafka/
â”‚
â”œâ”€â”€ ğŸ“Š monitoring/                        # Monitoring vÃ  logging
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ ğŸ§ª tests/                            # Test cases
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ ğŸ“‹ docs/                             # Documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ deployment.md
â”‚   â””â”€â”€ troubleshooting.md
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml                # Docker services
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python dependencies
â”œâ”€â”€ ğŸ”§ Makefile                         # Build automation
â”œâ”€â”€ ğŸ”‘ .env.example                     # Environment variables template
â””â”€â”€ ğŸ“– README.md                        # Project documentation
# ğŸ“ LiÃªn há»‡
- Maintainer: Vanhaydoi
- Email: nguyenduyvanhaydoi1512@gmail.com
